# Phi-2 RAG Chatbot for Sibu

This is a Retrieval-Augmented Generation (RAG) chatbot powered by the [Phi-2](https://huggingface.co/microsoft/phi-2) language model fine-tuned using QLoRA. The system is designed to answer questions specifically related to **Sibu, Sarawak**, using a local tourism PDF as its knowledge base.

---

## Directory Structure
â”œâ”€â”€ api/
â”‚ â”œâ”€â”€ app.py # Flask API to serve chatbot
â”‚ â””â”€â”€ chatbot.py # Main chatbot logic with RAG + QLoRA
â”œâ”€â”€ classifier/
â”‚ â””â”€â”€ filter.py # Topic filter for Sibu-related questions
â”œâ”€â”€ conversation/
â”‚ â””â”€â”€ memory.py # Sliding window memory for chat history
â”œâ”€â”€ data/
â”‚ â””â”€â”€ malaysian_english.jsonl # Fine-tuning data for QLoRA
â”œâ”€â”€ pdf2vault/
â”‚ â”œâ”€â”€ 07-GUIDE-SIBU-CENTRAL-v2.pdf # Core document used for RAG
â”‚ â””â”€â”€ Short-Info_Sibu_latest.pdf # Optional secondary PDF
â”œâ”€â”€ test/
â”‚ â”œâ”€â”€ rag_test.py # Test RAG setup with base model
â”‚ â””â”€â”€ rag_and_qlora_test.py # Test response with QLoRA adapter
â”œâ”€â”€ qlora_train.py # QLoRA fine-tuning script
â””â”€â”€ README.md # This file

---

## How to Use

### Step 1: Test Base Model and RAG Setup

Ensure FAISS, vector store, and PDF OCR are working with the base model.

```bash
python3 test/rag_test.py
```

### Step 2: Train Phi-2 with QLoRA

Fine-tune microsoft/phi-2 using your custom dataset.

```bash
python3 test/rag_test.py
```
This uses 4-bit quantization and trains q_proj and v_proj using LoRA.

### Step 3: âœ… Test RAG with QLoRA Adapter
Load the fine-tuned model and test it on relevant questions.

```bash
python3 test/rag_and_qlora_test.py
```

### Step 4: ðŸ§© Run Chatbot as REST API
Start the Flask API server.

```bash
python3 api/app.py #or python3 -m api.app
```
Then send a test request:

```bash
curl -X POST http://localhost:5000/ask \
     -H "Content-Type: application/json" \
     -d '{"question": "Where is Tua Pek Kong temple in Sibu?"}'
```

## Features
- Context-aware, retrieval-grounded chatbot
- Offline operation, no external API calls
- Domain-restricted to Sibu via topic filter
- OCR fallback for PDF text extraction
- Trained and inferenced using 4-bit QLoRA on 4GB VRAM GPU

## References
- microsoft/phi-2 â€” Base language model
- Sentence Transformers â€” for vector embeddings
- LangChain + FAISS â€” document vector storage
- PyTesseract + pdf2image â€” OCR for scanned PDFs
- HuggingFace QLoRA + PEFT â€” efficient fine-tuning

## Requirements
Install dependencies:

```bash
pip3 install -r requirements.txt
```

Ensure you have installed:
- CUDA 12.1 (compatible with your GPU).
- poppler-utils (for pdf2image)
- tesseract-ocr (for OCR fallback)